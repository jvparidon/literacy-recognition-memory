{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display plots inline\n",
    "%matplotlib notebook\n",
    "\n",
    "# imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "from bambi import Model, Prior\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "import pymc3_utils as pmu\n",
    "\n",
    "# suppress system warnings for legibility\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# resize plots to fit labels inside bounding box\n",
    "from matplotlib import rcParams\n",
    "rcParams.update({'figure.autolayout': True})\n",
    "\n",
    "# MPI color scheme\n",
    "sns.set(style='white', palette='Set2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raven's Progressive Matrices\n",
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start by loading the data\n",
    "df_ravens = pd.read_csv('data/ravens.tsv', sep='\\t').dropna()\n",
    "df_reading = pd.read_csv('data/tamil_reading.tsv', sep='\\t').drop(columns=['literate', 'subject'])\n",
    "df_ravens = df_ravens.merge(df_reading, left_on='pp', right_on='pp')\n",
    "\n",
    "display(df_ravens.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data mangling and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# standardize reading score\n",
    "df_ravens['reading_z'] = pmu.standardize(df_ravens['word'])\n",
    "\n",
    "display(df_ravens.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will set some parameters for the regression procedure, as outlined in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default model params\n",
    "defaults = {\n",
    "    'samples': 5000,\n",
    "    'tune': 2500,\n",
    "    'chains': 4,\n",
    "    'init': 'advi+adapt_diag',\n",
    "    'family': 'bernoulli',\n",
    "    'priors': {'fixed': 'narrow', 'random': 'narrow'},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are modelling each question in the ravens task as a Bernoulli trial (i.e., a generalized linear model). We will run the only model that works in the context of our multilevel model setup: A model with no fixed effects, only an overall intercept and by-participant and by-item intercepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ravens_intercept = Model(df_ravens)\n",
    "model_ravens_intercept.fit('ACC ~ 1',\n",
    "                           random=['1|item', '1|pp'],\n",
    "                           **defaults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pmu.summary(model_ravens_intercept.backend.trace).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\\(\\hat{r}\\\\) values look good, as does the number of effective samples for the by-participant intercepts. Even for the overall intercept we have 8.5K effective samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot model traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an additional check, we will plot the posterior traces for the selected model. Ideally these look unimodal and roughly normal. The plots on the righthand side should look like fuzzy caterpillars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g_traces = pm.traceplot(model_ravens_intercept.backend.trace)\n",
    "plt.savefig('figures/ravens_model_traces.png', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting participant intercept modes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now extract and store the posterior modes of the participant intercepts so we can use them to model reading scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pps = df_ravens['pp'].unique()\n",
    "pp_nums = [f'1|pp__{i}' for i in range(len(pps))]\n",
    "df_intercepts = pmu.summary(model_ravens_intercept.backend.trace).loc[pp_nums]\n",
    "df_intercepts['pp'] = np.sort(pps)\n",
    "\n",
    "display(df_intercepts.head().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uncorrected = df_ravens.groupby('pp', as_index=False).mean().rename(columns={'ACC': 'raw_ravens_mean'})\n",
    "df_intercepts = df_intercepts[['pp', 'mode']].rename(columns={'mode': 'ravens_intercept'})\n",
    "df_intercepts = df_intercepts.merge(df_uncorrected[['pp', 'reading_z', 'raw_ravens_mean']],\n",
    "                                    left_on='pp', right_on='pp').reset_index()\n",
    "\n",
    "display(df_intercepts.head().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and write to file\n",
    "df_intercepts.to_csv('data/ravens_intercepts.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before closing this notebook, we will take a quick look at the correlations between ravens score and reading score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_intercepts[['raw_ravens_mean', 'ravens_intercept', 'reading_z']].corr().round(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
